from six import iteritems

# ', \n'.join('\'{}\': None'.format(k) for k in valid_losses.keys())
torch2tf_losses = {
    'BCELoss': 'BinaryCrossentropy',
    'BCEWithLogitsLoss': None,
    'CTCLoss': None,
    'CosineEmbeddingLoss': None,
    'CrossEntropyLoss': None,
    'F': None,
    'HingeEmbeddingLoss': None,
    'KLDivLoss': None,
    'L1Loss': None,
    'MSELoss': None,
    'MarginRankingLoss': None,
    'Module': None,
    'MultiLabelMarginLoss': None,
    'MultiLabelSoftMarginLoss': None,
    'MultiMarginLoss': None,
    'NLLLoss': None,
    'NLLLoss2d': None,
    'PoissonNLLLoss': None,
    'SmoothL1Loss': None,
    'SoftMarginLoss': None,
    'TripletMarginLoss': None
}

tf2torch_losses = {v: k for k, v in iteritems(torch2tf_losses)}

# ', \n'.join('\'{}\''.format(k) for k in valid_losses.keys())
tf_losses = tuple((
    'BinaryCrossentropy',
    'CategoricalCrossentropy',
    'CategoricalHinge',
    'CosineSimilarity',
    'Hinge',
    'Huber',
    'KLD',
    'KLDivergence',
    'LogCosh',
    'Loss',
    'MAE',
    'MAPE',
    'MSE',
    'MSLE',
    'MeanAbsoluteError',
    'MeanAbsolutePercentageError',
    'MeanSquaredError',
    'MeanSquaredLogarithmicError',
    'Poisson',
    'Reduction',
    'SparseCategoricalCrossentropy',
    'SquaredHinge',
    'binary_crossentropy',
    'categorical_crossentropy',
    'categorical_hinge',
    'cosine',
    'cosine_proximity',
    'cosine_similarity',
    'deserialize',
    'get',
    'hinge',
    'kld',
    'kullback_leibler_divergence',
    'logcosh',
    'mae',
    'mape',
    'mean_absolute_error',
    'mean_absolute_percentage_error',
    'mean_squared_error',
    'mean_squared_logarithmic_error',
    'mse',
    'msle',
    'poisson',
    'serialize',
    'sparse_categorical_crossentropy',
    'squared_hinge',
    'BinaryCrossentropyWithRanking',
    'DiceLoss',
    'JaccardDistance',
    'Kappa',
    'PairLoss',
    'SmoothL1',
    'SoftAUC'
))
